{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e6e43de",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6215bfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install albumentations -U #https://albumentations.ai/docs/getting_started/installation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bacbbb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import re, glob\n",
    "from six import BytesIO\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib.image import imread\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cc0cc8",
   "metadata": {},
   "source": [
    "## Load the Training Set (from PascalVOC to DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b0d893d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>XMin</th>\n",
       "      <th>YMin</th>\n",
       "      <th>XMax</th>\n",
       "      <th>YMax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>F:/Downloads/projects/hand-gestures/data_for_o...</td>\n",
       "      <td>option3</td>\n",
       "      <td>0.7365</td>\n",
       "      <td>0.274536</td>\n",
       "      <td>0.8210</td>\n",
       "      <td>0.526525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>F:/Downloads/projects/hand-gestures/data_for_o...</td>\n",
       "      <td>option3</td>\n",
       "      <td>0.2470</td>\n",
       "      <td>0.365341</td>\n",
       "      <td>0.4655</td>\n",
       "      <td>0.880720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                                               path    label    XMin  \\\n",
       "0  TRAIN  F:/Downloads/projects/hand-gestures/data_for_o...  option3  0.7365   \n",
       "1  TRAIN  F:/Downloads/projects/hand-gestures/data_for_o...  option3  0.2470   \n",
       "\n",
       "       YMin    XMax      YMax  \n",
       "0  0.274536  0.8210  0.526525  \n",
       "1  0.365341  0.4655  0.880720  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training set\n",
    "df_train = pd.DataFrame(columns=['type','path','label','XMin','YMin','XMax','YMax'])\n",
    "df_train.head()\n",
    "\n",
    "# path to the image files\n",
    "path_to_images = \"F:/Downloads/projects/hand-gestures/data_for_object_detection/data/\"\n",
    "\n",
    "# path to the annotation files (in xml format)\n",
    "directory_in_str = \"F:/Downloads/projects/hand-gestures/data_for_object_detection/xml/\"\n",
    "directory = os.fsencode(directory_in_str)\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "\n",
    "    if filename.endswith(\".xml\"):\n",
    "        name = os.path.splitext(filename)[0]\n",
    "        path = directory_in_str + filename\n",
    "        \n",
    "        # X divided by the width\n",
    "        # Y divided by the height\n",
    "        # how to calculate normalized coordinates: https://stackoverflow.com/questions/48915003/get-the-bounding-box-coordinates-in-the-tensorflow-object-detection-api-tutorial\n",
    "\n",
    "        tree = ET.parse(path)\n",
    "        root = tree.getroot()\n",
    "        image_name = path_to_images + root.find('filename').text\n",
    "        \n",
    "        for size in root.findall('size'):\n",
    "            width = int(size.find('width').text)\n",
    "            height = int(size.find('height').text)\n",
    "            \n",
    "        for object in root.findall('object'):\n",
    "            label_type = object.find('name').text\n",
    "            for bndbox in object.findall('bndbox'):\n",
    "                xmin = int(bndbox.find('xmin').text) / width\n",
    "                xmax = int(bndbox.find('xmax').text) / width\n",
    "                ymin = int(bndbox.find('ymin').text) / height\n",
    "                ymax = int(bndbox.find('ymax').text) / height\n",
    "                \n",
    "                new_row = {\n",
    "                 'type':\"TRAIN\",\n",
    "                 'path':image_name,\n",
    "                 'label':label_type,\n",
    "                 'XMin':xmin,\n",
    "                 'YMin':ymin,\n",
    "                 'XMax':xmax,\n",
    "                 'YMax':ymax,\n",
    "                 }\n",
    "\n",
    "                df_train = df_train.append(new_row, ignore_index=True)\n",
    "\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c0d5d6",
   "metadata": {},
   "source": [
    "## Define Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e64ba1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_0 = A.Compose([\n",
    "    A.SafeRotate(p=1, limit=[-90, -90]),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "    A.PixelDropout(p=0.5),\n",
    "], bbox_params=A.BboxParams(format='albumentations', min_area=1024, min_visibility=0.6))\n",
    "\n",
    "transform_1 = A.Compose([\n",
    "    A.SafeRotate(p=1, limit=[90, 90]),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "    A.PixelDropout(p=0.5),\n",
    "], bbox_params=A.BboxParams(format='albumentations', min_area=1024, min_visibility=0.6))\n",
    "\n",
    "transform_2 = A.Compose([\n",
    "    A.HorizontalFlip(p=1),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "    A.PixelDropout(p=0.5),\n",
    "], bbox_params=A.BboxParams(format='albumentations', min_area=1024, min_visibility=0.6))\n",
    "\n",
    "transforms = [transform_0, transform_1, transform_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff7bd65",
   "metadata": {},
   "source": [
    "## Run Image Augmentation for Each Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afec6f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    image = imread(row.path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    file_path, file_extension = os.path.splitext(row.path)\n",
    "    file_name = os.path.basename(file_path)\n",
    "    \n",
    "    bboxes = []\n",
    "    bboxes.append([row.XMin, row.YMin, row.XMax, row.YMax, row.label])\n",
    "    \n",
    "    i = 0\n",
    "    for transform in transforms:\n",
    "        transformed = transform(image=image, bboxes=bboxes)\n",
    "        transformed_image = transformed['image']\n",
    "        transformed_bboxes = transformed['bboxes']\n",
    "\n",
    "        augmented_img_path = 'F:/Downloads/projects/hand-gestures/data_for_object_detection/augmented/data/'+file_name+'_a'+str(i)+file_extension\n",
    "        cv2.imwrite(augmented_img_path, transformed_image)\n",
    "\n",
    "        tree = ET.parse('F:/Downloads/projects/hand-gestures/data_for_object_detection/xml/'+file_name+'.xml')\n",
    "        root = tree.getroot()\n",
    "\n",
    "        height, width, _ = transformed_image.shape\n",
    "\n",
    "        for size in root.findall('size'):\n",
    "            size.find('width').text = str(width)\n",
    "            size.find('height').text = str(height)\n",
    "\n",
    "        xmin, ymin, xmax, ymax, label = transformed_bboxes[0]\n",
    "        for object in root.findall('object'):\n",
    "            label_type = object.find('name').text\n",
    "            for bndbox in object.findall('bndbox'):\n",
    "                bndbox.find('xmin').text = str(xmin * width)\n",
    "                bndbox.find('xmax').text = str(xmax * width)\n",
    "                bndbox.find('ymin').text = str(ymin * height)\n",
    "                bndbox.find('ymax').text = str(ymax * height)\n",
    "\n",
    "        tree.write('F:/Downloads/projects/hand-gestures/data_for_object_detection/augmented/xml/'+file_name+'_a'+str(i)+'.xml')\n",
    "        \n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73715e0f",
   "metadata": {},
   "source": [
    "## Load the Augmented Training Set into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7940848d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>XMin</th>\n",
       "      <th>YMin</th>\n",
       "      <th>XMax</th>\n",
       "      <th>YMax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>F:/Downloads/projects/hand-gestures/data_for_o...</td>\n",
       "      <td>option3</td>\n",
       "      <td>0.7365</td>\n",
       "      <td>0.274536</td>\n",
       "      <td>0.8210</td>\n",
       "      <td>0.526525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>F:/Downloads/projects/hand-gestures/data_for_o...</td>\n",
       "      <td>option3</td>\n",
       "      <td>0.2745</td>\n",
       "      <td>0.736074</td>\n",
       "      <td>0.5265</td>\n",
       "      <td>0.820955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                                               path    label    XMin  \\\n",
       "0  TRAIN  F:/Downloads/projects/hand-gestures/data_for_o...  option3  0.7365   \n",
       "1  TRAIN  F:/Downloads/projects/hand-gestures/data_for_o...  option3  0.2745   \n",
       "\n",
       "       YMin    XMax      YMax  \n",
       "0  0.274536  0.8210  0.526525  \n",
       "1  0.736074  0.5265  0.820955  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training set\n",
    "df_train = pd.DataFrame(columns=['type','path','label','XMin','YMin','XMax','YMax'])\n",
    "df_train.head()\n",
    "\n",
    "# path to the image files\n",
    "path_to_images = \"F:/Downloads/projects/hand-gestures/data_for_object_detection/augmented/merged/data/\"\n",
    "\n",
    "# path to the annotation files (in xml format)\n",
    "directory_in_str = \"F:/Downloads/projects/hand-gestures/data_for_object_detection/augmented/merged/xml/\"\n",
    "directory = os.fsencode(directory_in_str)\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "\n",
    "    if filename.endswith(\".xml\"):\n",
    "        name = os.path.splitext(filename)[0]\n",
    "        path = directory_in_str + filename\n",
    "        \n",
    "        # X divided by the width\n",
    "        # Y divided by the height\n",
    "        # how to calculate normalized coordinates: https://stackoverflow.com/questions/48915003/get-the-bounding-box-coordinates-in-the-tensorflow-object-detection-api-tutorial\n",
    "\n",
    "        tree = ET.parse(path)\n",
    "        root = tree.getroot()\n",
    "        image_name = path_to_images + root.find('filename').text\n",
    "        \n",
    "        for size in root.findall('size'):\n",
    "            width = int(size.find('width').text)\n",
    "            height = int(size.find('height').text)\n",
    "            \n",
    "        for object in root.findall('object'):\n",
    "            label_type = object.find('name').text\n",
    "            for bndbox in object.findall('bndbox'):\n",
    "                xmin = int(float(bndbox.find('xmin').text)) / width\n",
    "                xmax = int(float(bndbox.find('xmax').text)) / width\n",
    "                ymin = int(float(bndbox.find('ymin').text)) / height\n",
    "                ymax = int(float(bndbox.find('ymax').text)) / height\n",
    "                \n",
    "                new_row = {\n",
    "                 'type':\"TRAIN\",\n",
    "                 'path':image_name,\n",
    "                 'label':label_type,\n",
    "                 'XMin':xmin,\n",
    "                 'YMin':ymin,\n",
    "                 'XMax':xmax,\n",
    "                 'YMax':ymax,\n",
    "                 }\n",
    "\n",
    "                df_train = df_train.append(new_row, ignore_index=True)\n",
    "\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52d4c81",
   "metadata": {},
   "source": [
    "## Count of Each Class after Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "694a1b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>option3</th>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>back</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ok</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>option1</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>option2</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>option4</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thumb</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>punch</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label\n",
       "option3    404\n",
       "back       400\n",
       "ok         400\n",
       "option1    400\n",
       "option2    400\n",
       "option4    400\n",
       "thumb      400\n",
       "punch      400"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.label.value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8beec73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3204"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.label.value_counts().to_frame().sum()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf7c3e7",
   "metadata": {},
   "source": [
    "## Count of File Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc608d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'.jpg': 121, '.xml': 3204, '.JPG': 3288, '.jpeg': 8, '.JPEG': 428})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "import os\n",
    "\n",
    "cnt = collections.Counter()\n",
    "def get_file_format_count():\n",
    "    for root_dir, sub_dirs, files in os.walk(\"F:/Downloads/projects/hand-gestures/data_for_object_detection/augmented/merged/data/\"):\n",
    "        for filename in files:\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            cnt[ext] += 1\n",
    "    return cnt\n",
    "\n",
    "get_file_format_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ab286d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
